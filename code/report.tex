\documentclass[letter,11pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}

%opening
\title{Using NLP Techniques for File Fragment Classification}
\author{Simran Fitzgerald, George Mathews, Colin Morris and Oles Zhulyn}

\begin{document}

\maketitle

\begin{abstract}
The classification of file fragments is an important problem in digital forensics. The literature does not include a lot of work that involves applying machine learning techniques to this problem. In this work, we explore the use of techniques from natural language processing to classify file fragments. We took a supervised learning approach, based on the use of support vector machines combined with the bag-of-words model, where text documents are represented as unordered bags of words. This technique has been repeatedly shown to be effective and robust in classifying text documents (e.g., in distinguishing positive movie reviews from negative ones).

In our approach, we represent file fragments as ``bags of bytes'' with feature vectors consisting of unigram and bigram counts, as well as other statistical measurements (including entropy and others). We made use of the publicly available Garfinkel data corpus to generate file fragments for training and testing. We ran a series of experiments, and found that this approach is effective and robust in this domain as well.
\end{abstract}

\section{Introduction}
\label{Section:Introduction}
The classification of file fragments is an important problem in digital forensics, particularly for the purpose of carving fragmented files. Files that are not stored contiguously on the hard drive must be carefully reconstructed from fragments based on their content during file carving. Because the search space for fragments belonging to a particular file is so large, it is essential to have an automated method for distinguishing whether a fragment potentially belongs to a file or not. For example, a fragment from a TXT file certainly does not belong to a JPEG file. Garfinkel \cite{Garfinkel07} observes that although the fragmentation of files is relatively rare on today's file systems, the files of interest in forensic investigations are more likely to be fragmented than other files. For example, large files that have been modified numerous times over a long period of time on a hard drive that is filled near capacity will likely exhibit fragmentation.




The paper is organized as follows. In Section \ref{Section:RelatedWork}, we provide a brief overview of related work done in this area. In Section \ref{Section:ExperimentalSetup}, we describe our experimental setup, which includes how we generated the data set we used in training and testing. In Section \ref{Section:Results}, we present our results. We conclude and suggest future directions for this work in Section \ref{Section:ConclusionAndFutureWork}.

\section{Related work}
\label{Section:RelatedWork}
TODO \cite{Conti10, Garfinkel09, Axelsson10, Calhoun08, Li10}

\section{Experimental setup}
\label{Section:ExperimentalSetup}
TODO

\section{Results}
\label{Section:Results}
TODO

\section{Conclusion and future work}
\label{Section:ConclusionAndFutureWork}
TODO

\section*{Acknowledgements}
We are grateful to Greg Conti for his help.


% References
\newpage
\bibliographystyle{plain}
\bibliography{report}

\end{document}
